{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "[Scikit-learn](http://scikit-learn.org/stable/) is a python-based machine learning library providing implementations of a great many algorithms for supervised and unsupervised learning. In large part, it builds upon the cabilities of NumPy, SciPy, matplotlib, and Pandas. \n",
    "\n",
    "In the context of supervised learning, the primary objects scikit-learn defines are called **estimators**. Each of these defines a `fit` method, which develops a model from provided training data, and a `predict` method, which uses the model to map a new instance to a suitable target value. Scikit-learn also defines multiple utilities for partitioning and manipulating data sets as well as  evaluating models. \n",
    "\n",
    "Below, we cover some of the basic steps needed to create a model in scikit-learn.  These notes are based on material appearing in the *scikit-learn tutorials*.\n",
    "\n",
    "*  http://scikit-learn.org/stable/tutorial/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builtin Datasets\n",
    "\n",
    "Scikit-learn comes bundled with several pre-defined (typically small) `datasets` that users can explore. \n",
    "\n",
    "    load_boston()\tLoad and return the boston house-prices dataset (regression).\n",
    "    load_iris()\tLoad and return the iris dataset (classification).\n",
    "    load_diabetes()\tLoad and return the diabetes dataset (regression).\n",
    "    load_digits()\tLoad and return the digits dataset (classification).\n",
    "    load_linnerud()\tLoad and return the linnerud dataset (multivariate regression).\n",
    "    load_wine()\tLoad and return the wine dataset (classification).\n",
    "    load_breast_cancer()\tLoad and return the breast cancer wisconsin dataset (classification).\n",
    "\n",
    "The iris dataset is loaded below, and a description of it is printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ".. _iris_dataset:\n\nIris plants dataset\n--------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 150 (50 in each of three classes)\n    :Number of Attributes: 4 numeric, predictive attributes and the class\n    :Attribute Information:\n        - sepal length in cm\n        - sepal width in cm\n        - petal length in cm\n        - petal width in cm\n        - class:\n                - Iris-Setosa\n                - Iris-Versicolour\n                - Iris-Virginica\n                \n    :Summary Statistics:\n\n    ============== ==== ==== ======= ===== ====================\n                    Min  Max   Mean    SD   Class Correlation\n    ============== ==== ==== ======= ===== ====================\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n    ============== ==== ==== ======= ===== ====================\n\n    :Missing Attribute Values: None\n    :Class Distribution: 33.3% for each of 3 classes.\n    :Creator: R.A. Fisher\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n    :Date: July, 1988\n\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\nfrom Fisher's paper. Note that it's the same as in R, but not as in the UCI\nMachine Learning Repository, which has two wrong data points.\n\nThis is perhaps the best known database to be found in the\npattern recognition literature.  Fisher's paper is a classic in the field and\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\ndata set contains 3 classes of 50 instances each, where each class refers to a\ntype of iris plant.  One class is linearly separable from the other 2; the\nlatter are NOT linearly separable from each other.\n\n.. topic:: References\n\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n     Mathematical Statistics\" (John Wiley, NY, 1950).\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n     Structure and Classification Rule for Recognition in Partially Exposed\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n     on Information Theory, May 1972, 431-433.\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n     conceptual clustering system finds 3 classes in the data.\n   - Many, many more ...\n"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import sklearn.tree as tree\n",
    "import numpy as np\n",
    "iris = datasets.load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data sets we typically deal with are tabular. In scikit-learn, the input attributes (features) and the targets are stored in separate arrays. E.g., the `iris` data sets consists of 150 separate observations of 5 attributes. This, however, is split into arrays of shape (150,4) and (150,), respectively. The first is a 2d array, and the second is 1d. \n",
    "\n",
    "We can access the input and targets using `iris.data` and `iris.target`, respectively. Note that these are stored in NumPy `ndarray` objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "input datatype= <class 'numpy.ndarray'>\ninput shape (2d array)= (150, 4)\n\ninput features:\n\t sepal length (cm)\n\t sepal width (cm)\n\t petal length (cm)\n\t petal width (cm)\n\ntarget datatype= <class 'numpy.ndarray'>\ntarget shape (2d array)= (150,)\n\ntarget values:\n\t setosa\n\t versicolor\n\t virginica\n"
    }
   ],
   "source": [
    "print(\"input datatype=\",type(iris.data))\n",
    "print(\"input shape (2d array)=\",iris.data.shape)\n",
    "print(\"\\ninput features:\")\n",
    "for name in iris.feature_names:\n",
    "    print(\"\\t\",name)\n",
    "\n",
    "print(\"\\ntarget datatype=\", type(iris.target))\n",
    "print(\"target shape (2d array)=\",iris.target.shape)\n",
    "print(\"\\ntarget values:\")\n",
    "for name in iris.target_names:\n",
    "    print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[5.1 3.5 1.4 0.2] target: 0\n[4.9 3.  1.4 0.2] target: 0\n[4.7 3.2 1.3 0.2] target: 0\n[4.6 3.1 1.5 0.2] target: 0\n[5.  3.6 1.4 0.2] target: 0\n[5.4 3.9 1.7 0.4] target: 0\n[4.6 3.4 1.4 0.3] target: 0\n[5.  3.4 1.5 0.2] target: 0\n[4.4 2.9 1.4 0.2] target: 0\n[4.9 3.1 1.5 0.1] target: 0\n[5.4 3.7 1.5 0.2] target: 0\n[4.8 3.4 1.6 0.2] target: 0\n[4.8 3.  1.4 0.1] target: 0\n[4.3 3.  1.1 0.1] target: 0\n[5.8 4.  1.2 0.2] target: 0\n[5.7 4.4 1.5 0.4] target: 0\n[5.4 3.9 1.3 0.4] target: 0\n[5.1 3.5 1.4 0.3] target: 0\n[5.7 3.8 1.7 0.3] target: 0\n[5.1 3.8 1.5 0.3] target: 0\ntarget values:  [0 1 2]\nnumber of class 0 = 50\nnumber of class 1 = 50\nnumber of class 2 = 50\n"
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(iris.data[i],\"target:\",iris.target[i])\n",
    "    \n",
    "print(\"target values: \", np.unique(iris.target))\n",
    "\n",
    "for i in  np.unique(iris.target):\n",
    "    print(\"number of class\", i, \"=\",np.sum(iris.target == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators\n",
    "\n",
    "Learning and prediction in scikit-learn takes place using so-called estimator objects. Each esitmator implements two methods, `fit` and `predict`.\n",
    "Below, we train a decision tree estimator on all but the last instance of the data set, and then use the developed model to classify the last instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "  * **See:** http://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Instance: [5.9 3.  5.1 1.8]\nPredicted: [2]\nActual: 2\n"
    }
   ],
   "source": [
    "# from sklearn import tree\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree.fit(iris.data[:-1], iris.target[:-1])  \n",
    "print(\"Instance:\", iris.data[-1])\n",
    "print(\"Predicted:\", dtree.predict([iris.data[-1]]))\n",
    "print(\"Actual:\", iris.target[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll train on all but the last 50. This is a horrible idea in this case, because the data in `iris` is sorted by class. And so by training on the first 100 examples, we miss class 2 completely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Instance: [6.3 3.3 6.  2.5] Predicted: [1] Actual: 2\nInstance: [5.8 2.7 5.1 1.9] Predicted: [1] Actual: 2\nInstance: [7.1 3.  5.9 2.1] Predicted: [1] Actual: 2\nInstance: [6.3 2.9 5.6 1.8] Predicted: [1] Actual: 2\nInstance: [6.5 3.  5.8 2.2] Predicted: [1] Actual: 2\nInstance: [7.6 3.  6.6 2.1] Predicted: [1] Actual: 2\nInstance: [4.9 2.5 4.5 1.7] Predicted: [1] Actual: 2\nInstance: [7.3 2.9 6.3 1.8] Predicted: [1] Actual: 2\nInstance: [6.7 2.5 5.8 1.8] Predicted: [1] Actual: 2\nInstance: [7.2 3.6 6.1 2.5] Predicted: [1] Actual: 2\nInstance: [6.5 3.2 5.1 2. ] Predicted: [1] Actual: 2\nInstance: [6.4 2.7 5.3 1.9] Predicted: [1] Actual: 2\nInstance: [6.8 3.  5.5 2.1] Predicted: [1] Actual: 2\nInstance: [5.7 2.5 5.  2. ] Predicted: [1] Actual: 2\nInstance: [5.8 2.8 5.1 2.4] Predicted: [1] Actual: 2\nInstance: [6.4 3.2 5.3 2.3] Predicted: [1] Actual: 2\nInstance: [6.5 3.  5.5 1.8] Predicted: [1] Actual: 2\nInstance: [7.7 3.8 6.7 2.2] Predicted: [1] Actual: 2\nInstance: [7.7 2.6 6.9 2.3] Predicted: [1] Actual: 2\nInstance: [6.  2.2 5.  1.5] Predicted: [1] Actual: 2\nInstance: [6.9 3.2 5.7 2.3] Predicted: [1] Actual: 2\nInstance: [5.6 2.8 4.9 2. ] Predicted: [1] Actual: 2\nInstance: [7.7 2.8 6.7 2. ] Predicted: [1] Actual: 2\nInstance: [6.3 2.7 4.9 1.8] Predicted: [1] Actual: 2\nInstance: [6.7 3.3 5.7 2.1] Predicted: [1] Actual: 2\nInstance: [7.2 3.2 6.  1.8] Predicted: [1] Actual: 2\nInstance: [6.2 2.8 4.8 1.8] Predicted: [1] Actual: 2\nInstance: [6.1 3.  4.9 1.8] Predicted: [1] Actual: 2\nInstance: [6.4 2.8 5.6 2.1] Predicted: [1] Actual: 2\nInstance: [7.2 3.  5.8 1.6] Predicted: [1] Actual: 2\nInstance: [7.4 2.8 6.1 1.9] Predicted: [1] Actual: 2\nInstance: [7.9 3.8 6.4 2. ] Predicted: [1] Actual: 2\nInstance: [6.4 2.8 5.6 2.2] Predicted: [1] Actual: 2\nInstance: [6.3 2.8 5.1 1.5] Predicted: [1] Actual: 2\nInstance: [6.1 2.6 5.6 1.4] Predicted: [1] Actual: 2\nInstance: [7.7 3.  6.1 2.3] Predicted: [1] Actual: 2\nInstance: [6.3 3.4 5.6 2.4] Predicted: [1] Actual: 2\nInstance: [6.4 3.1 5.5 1.8] Predicted: [1] Actual: 2\nInstance: [6.  3.  4.8 1.8] Predicted: [1] Actual: 2\nInstance: [6.9 3.1 5.4 2.1] Predicted: [1] Actual: 2\nInstance: [6.7 3.1 5.6 2.4] Predicted: [1] Actual: 2\nInstance: [6.9 3.1 5.1 2.3] Predicted: [1] Actual: 2\nInstance: [5.8 2.7 5.1 1.9] Predicted: [1] Actual: 2\nInstance: [6.8 3.2 5.9 2.3] Predicted: [1] Actual: 2\nInstance: [6.7 3.3 5.7 2.5] Predicted: [1] Actual: 2\nInstance: [6.7 3.  5.2 2.3] Predicted: [1] Actual: 2\nInstance: [6.3 2.5 5.  1.9] Predicted: [1] Actual: 2\nInstance: [6.5 3.  5.2 2. ] Predicted: [1] Actual: 2\nInstance: [6.2 3.4 5.4 2.3] Predicted: [1] Actual: 2\nInstance: [5.9 3.  5.1 1.8] Predicted: [1] Actual: 2\n\nincorrect classifications:  50\nmanual accuracy calculation:  0.0\nbuilt-in accuracy calculation 1: 0.0\nbuilt-in accuracy calculation 2: 0.0\n"
    }
   ],
   "source": [
    "iris_x = iris.data.copy()\n",
    "iris_y = iris.target.copy()\n",
    "iris_x_train = iris_x[:-50]\n",
    "iris_y_train = iris_y[:-50]\n",
    "iris_x_test  = iris_x[-50:]\n",
    "iris_y_test  = iris_y[-50:]\n",
    "dtree.fit(iris_x_train, iris_y_train) \n",
    "#dtree.predict(iris_x_test)\n",
    "\n",
    "count = 0\n",
    "for i in range(50):\n",
    "    print(\"Instance:\", iris_x_test[i], \"Predicted:\", dtree.predict([iris_x_test[i]]), \"Actual:\", iris_y_test[i])\n",
    "    if dtree.predict([iris_x_test[i]])[0] != iris_y_test[i]:\n",
    "        count = count + 1\n",
    "\n",
    "print(\"\\nincorrect classifications: \", count)\n",
    "print(\"manual accuracy calculation: \", (1-count/50))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"built-in accuracy calculation 1:\", accuracy_score(dtree.predict(iris_x_test), iris_y_test))\n",
    "print(\"built-in accuracy calculation 2:\", dtree.score(iris_x_test, iris_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really, we need to shuffle the data before it is fed to the decision tree learner. We can do this using `np.random.permutation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance: [4.4 3.  1.3 0.2] Predicted: [0] Actual: 0\n",
      "Instance: [5.4 3.9 1.7 0.4] Predicted: [0] Actual: 0\n",
      "Instance: [5.5 2.3 4.  1.3] Predicted: [1] Actual: 1\n",
      "Instance: [6.8 3.2 5.9 2.3] Predicted: [2] Actual: 2\n",
      "Instance: [7.6 3.  6.6 2.1] Predicted: [2] Actual: 2\n",
      "Instance: [5.1 3.5 1.4 0.2] Predicted: [0] Actual: 0\n",
      "Instance: [4.9 3.1 1.5 0.2] Predicted: [0] Actual: 0\n",
      "Instance: [5.2 3.4 1.4 0.2] Predicted: [0] Actual: 0\n",
      "Instance: [5.7 2.8 4.5 1.3] Predicted: [1] Actual: 1\n",
      "Instance: [6.6 3.  4.4 1.4] Predicted: [1] Actual: 1\n",
      "Instance: [5.  3.2 1.2 0.2] Predicted: [0] Actual: 0\n",
      "Instance: [5.1 3.3 1.7 0.5] Predicted: [0] Actual: 0\n",
      "Instance: [6.4 2.9 4.3 1.3] Predicted: [1] Actual: 1\n",
      "Instance: [5.4 3.4 1.5 0.4] Predicted: [0] Actual: 0\n",
      "Instance: [7.7 2.6 6.9 2.3] Predicted: [2] Actual: 2\n",
      "Instance: [4.9 2.4 3.3 1. ] Predicted: [1] Actual: 1\n",
      "Instance: [7.9 3.8 6.4 2. ] Predicted: [2] Actual: 2\n",
      "Instance: [6.7 3.1 4.4 1.4] Predicted: [1] Actual: 1\n",
      "Instance: [5.2 4.1 1.5 0.1] Predicted: [0] Actual: 0\n",
      "Instance: [6.  3.  4.8 1.8] Predicted: [2] Actual: 2\n",
      "Instance: [5.8 4.  1.2 0.2] Predicted: [0] Actual: 0\n",
      "Instance: [7.7 2.8 6.7 2. ] Predicted: [2] Actual: 2\n",
      "Instance: [5.1 3.8 1.5 0.3] Predicted: [0] Actual: 0\n",
      "Instance: [4.7 3.2 1.6 0.2] Predicted: [0] Actual: 0\n",
      "Instance: [7.4 2.8 6.1 1.9] Predicted: [2] Actual: 2\n",
      "Instance: [5.  3.3 1.4 0.2] Predicted: [0] Actual: 0\n",
      "Instance: [6.3 3.4 5.6 2.4] Predicted: [2] Actual: 2\n",
      "Instance: [5.7 2.8 4.1 1.3] Predicted: [1] Actual: 1\n",
      "Instance: [5.8 2.7 3.9 1.2] Predicted: [1] Actual: 1\n",
      "Instance: [5.7 2.6 3.5 1. ] Predicted: [1] Actual: 1\n",
      "Instance: [6.4 3.2 5.3 2.3] Predicted: [2] Actual: 2\n",
      "Instance: [6.7 3.  5.2 2.3] Predicted: [2] Actual: 2\n",
      "Instance: [6.3 2.5 4.9 1.5] Predicted: [1] Actual: 1\n",
      "Instance: [6.7 3.  5.  1.7] Predicted: [2] Actual: 1\n",
      "Instance: [5.  3.  1.6 0.2] Predicted: [0] Actual: 0\n",
      "Instance: [5.5 2.4 3.7 1. ] Predicted: [1] Actual: 1\n",
      "Instance: [6.7 3.1 5.6 2.4] Predicted: [2] Actual: 2\n",
      "Instance: [5.8 2.7 5.1 1.9] Predicted: [2] Actual: 2\n",
      "Instance: [5.1 3.4 1.5 0.2] Predicted: [0] Actual: 0\n",
      "Instance: [6.6 2.9 4.6 1.3] Predicted: [1] Actual: 1\n",
      "Instance: [5.6 3.  4.1 1.3] Predicted: [1] Actual: 1\n",
      "Instance: [5.9 3.2 4.8 1.8] Predicted: [2] Actual: 1\n",
      "Instance: [6.3 2.3 4.4 1.3] Predicted: [1] Actual: 1\n",
      "Instance: [5.5 3.5 1.3 0.2] Predicted: [0] Actual: 0\n",
      "Instance: [5.1 3.7 1.5 0.4] Predicted: [0] Actual: 0\n",
      "Instance: [4.9 3.1 1.5 0.1] Predicted: [0] Actual: 0\n",
      "Instance: [6.3 2.9 5.6 1.8] Predicted: [2] Actual: 2\n",
      "Instance: [5.8 2.7 4.1 1. ] Predicted: [1] Actual: 1\n",
      "Instance: [7.7 3.8 6.7 2.2] Predicted: [2] Actual: 2\n",
      "Instance: [4.6 3.2 1.4 0.2] Predicted: [0] Actual: 0\n",
      "\n",
      "Incorrect classifications:  2\n",
      "manual accuracy calculation:  0.96\n",
      "built-in accuracy calculation 1: 0.96\n",
      "built-in accuracy calculation 2: 0.96\n"
     ]
    }
   ],
   "source": [
    "iris_x = iris.data.copy()\n",
    "iris_y = iris.target.copy()\n",
    "\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_x))\n",
    "\n",
    "iris_x_train = iris_x[indices[:-50]]\n",
    "iris_y_train = iris_y[indices[:-50]]\n",
    "iris_x_test  = iris_x[indices[-50:]]\n",
    "iris_y_test  = iris_y[indices[-50:]]\n",
    "\n",
    "dtree.fit(iris_x_train, iris_y_train) \n",
    "dtree.predict(iris_x_test)\n",
    "\n",
    "count = 0\n",
    "for i in range(50):\n",
    "    print(\"Instance:\", iris_x_test[i], \"Predicted:\", dtree.predict([iris_x_test[i]]), \"Actual:\", iris_y_test[i])\n",
    "    if dtree.predict([iris_x_test[i]])[0] != iris_y_test[i]:\n",
    "        count = count + 1\n",
    "print(\"\\nIncorrect classifications: \", count)\n",
    "print(\"manual accuracy calculation: \", (1-count/50))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"built-in accuracy calculation 1:\", accuracy_score(dtree.predict(iris_x_test), iris_y_test))\n",
    "print(\"built-in accuracy calculation 2:\", dtree.score(iris_x_test, iris_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3eb92041fe65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(dtree, out_file=None) \n",
    "print(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'graphviz' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5a805153c4ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PATH\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathsep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'C:/Program Files (x86)/Graphviz2.38/bin/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graphviz' is not defined"
     ]
    }
   ],
   "source": [
    "# For Windows, you might need to add graphviz to the PATH environment variable. \n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\n",
      "node [shape=box, style=\"filled, rounded\", color=\"black\", fontname=helvetica] ;\n",
      "edge [fontname=helvetica] ;\n",
      "0 [label=<petal length (cm) &le; 2.45<br/>gini = 0.665<br/>samples = 100<br/>value = [31, 33, 36]<br/>class = virginica>, fillcolor=\"#f9f6fe\"] ;\n",
      "1 [label=<gini = 0.0<br/>samples = 31<br/>value = [31, 0, 0]<br/>class = setosa>, fillcolor=\"#e58139\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "2 [label=<petal width (cm) &le; 1.65<br/>gini = 0.499<br/>samples = 69<br/>value = [0, 33, 36]<br/>class = virginica>, fillcolor=\"#f5effd\"] ;\n",
      "0 -> 2 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "3 [label=<petal length (cm) &le; 4.95<br/>gini = 0.193<br/>samples = 37<br/>value = [0, 33, 4]<br/>class = versicolor>, fillcolor=\"#51e890\"] ;\n",
      "2 -> 3 ;\n",
      "4 [label=<gini = 0.0<br/>samples = 32<br/>value = [0, 32, 0]<br/>class = versicolor>, fillcolor=\"#39e581\"] ;\n",
      "3 -> 4 ;\n",
      "5 [label=<sepal length (cm) &le; 6.05<br/>gini = 0.32<br/>samples = 5<br/>value = [0, 1, 4]<br/>class = virginica>, fillcolor=\"#a06aec\"] ;\n",
      "3 -> 5 ;\n",
      "6 [label=<petal width (cm) &le; 1.55<br/>gini = 0.5<br/>samples = 2<br/>value = [0, 1, 1]<br/>class = versicolor>, fillcolor=\"#ffffff\"] ;\n",
      "5 -> 6 ;\n",
      "7 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 0, 1]<br/>class = virginica>, fillcolor=\"#8139e5\"] ;\n",
      "6 -> 7 ;\n",
      "8 [label=<gini = 0.0<br/>samples = 1<br/>value = [0, 1, 0]<br/>class = versicolor>, fillcolor=\"#39e581\"] ;\n",
      "6 -> 8 ;\n",
      "9 [label=<gini = 0.0<br/>samples = 3<br/>value = [0, 0, 3]<br/>class = virginica>, fillcolor=\"#8139e5\"] ;\n",
      "5 -> 9 ;\n",
      "10 [label=<gini = 0.0<br/>samples = 32<br/>value = [0, 0, 32]<br/>class = virginica>, fillcolor=\"#8139e5\"] ;\n",
      "2 -> 10 ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(dtree, out_file=None, \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "print(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"376pt\" height=\"671pt\"\r\n",
       " viewBox=\"0.00 0.00 376.00 671.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 667)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-667 372,-667 372,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#f9f6fe\" stroke=\"black\" d=\"M218,-663C218,-663 77,-663 77,-663 71,-663 65,-657 65,-651 65,-651 65,-592 65,-592 65,-586 71,-580 77,-580 77,-580 218,-580 218,-580 224,-580 230,-586 230,-592 230,-592 230,-651 230,-651 230,-657 224,-663 218,-663\"/>\r\n",
       "<text text-anchor=\"start\" x=\"73\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 2.45</text>\r\n",
       "<text text-anchor=\"start\" x=\"110\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.665</text>\r\n",
       "<text text-anchor=\"start\" x=\"100\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\r\n",
       "<text text-anchor=\"start\" x=\"87\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 33, 36]</text>\r\n",
       "<text text-anchor=\"start\" x=\"97.5\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M117,-536.5C117,-536.5 20,-536.5 20,-536.5 14,-536.5 8,-530.5 8,-524.5 8,-524.5 8,-480.5 8,-480.5 8,-474.5 14,-468.5 20,-468.5 20,-468.5 117,-468.5 117,-468.5 123,-468.5 129,-474.5 129,-480.5 129,-480.5 129,-524.5 129,-524.5 129,-530.5 123,-536.5 117,-536.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"39.5\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"25\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 31</text>\r\n",
       "<text text-anchor=\"start\" x=\"16\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 0, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"22.5\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M120.091,-579.907C112.492,-568.652 104.231,-556.418 96.5931,-545.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"99.3914,-542.996 90.8948,-536.667 93.5901,-546.913 99.3914,-542.996\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"86.1364\" y=\"-557.51\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#f5effd\" stroke=\"black\" d=\"M294,-544C294,-544 159,-544 159,-544 153,-544 147,-538 147,-532 147,-532 147,-473 147,-473 147,-467 153,-461 159,-461 159,-461 294,-461 294,-461 300,-461 306,-467 306,-473 306,-473 306,-532 306,-532 306,-538 300,-544 294,-544\"/>\r\n",
       "<text text-anchor=\"start\" x=\"155\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.65</text>\r\n",
       "<text text-anchor=\"start\" x=\"189\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.499</text>\r\n",
       "<text text-anchor=\"start\" x=\"183\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 69</text>\r\n",
       "<text text-anchor=\"start\" x=\"170\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 33, 36]</text>\r\n",
       "<text text-anchor=\"start\" x=\"176.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.909,-579.907C180.914,-571.014 187.331,-561.509 193.529,-552.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.444,-554.267 199.14,-544.021 190.643,-550.35 196.444,-554.267\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"203.898\" y=\"-564.864\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#51e890\" stroke=\"black\" d=\"M217,-425C217,-425 76,-425 76,-425 70,-425 64,-419 64,-413 64,-413 64,-354 64,-354 64,-348 70,-342 76,-342 76,-342 217,-342 217,-342 223,-342 229,-348 229,-354 229,-354 229,-413 229,-413 229,-419 223,-425 217,-425\"/>\r\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.95</text>\r\n",
       "<text text-anchor=\"start\" x=\"109\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.193</text>\r\n",
       "<text text-anchor=\"start\" x=\"103\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 37</text>\r\n",
       "<text text-anchor=\"start\" x=\"94\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 33, 4]</text>\r\n",
       "<text text-anchor=\"start\" x=\"91\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.744,-460.907C192.663,-452.014 186.164,-442.509 179.889,-433.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.74,-431.3 174.207,-425.021 176.962,-435.251 182.74,-431.3\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M356,-417.5C356,-417.5 259,-417.5 259,-417.5 253,-417.5 247,-411.5 247,-405.5 247,-405.5 247,-361.5 247,-361.5 247,-355.5 253,-349.5 259,-349.5 259,-349.5 356,-349.5 356,-349.5 362,-349.5 368,-355.5 368,-361.5 368,-361.5 368,-405.5 368,-405.5 368,-411.5 362,-417.5 356,-417.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"278.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"264\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\r\n",
       "<text text-anchor=\"start\" x=\"255\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 32]</text>\r\n",
       "<text text-anchor=\"start\" x=\"257.5\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>2&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M254.603,-460.907C262.395,-449.652 270.864,-437.418 278.696,-426.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"281.724,-427.881 284.538,-417.667 275.968,-423.897 281.724,-427.881\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M115,-298.5C115,-298.5 12,-298.5 12,-298.5 6,-298.5 -7.10543e-015,-292.5 -7.10543e-015,-286.5 -7.10543e-015,-286.5 -7.10543e-015,-242.5 -7.10543e-015,-242.5 -7.10543e-015,-236.5 6,-230.5 12,-230.5 12,-230.5 115,-230.5 115,-230.5 121,-230.5 127,-236.5 127,-242.5 127,-242.5 127,-286.5 127,-286.5 127,-292.5 121,-298.5 115,-298.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"34.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\r\n",
       "<text text-anchor=\"start\" x=\"11\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 32, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M117.704,-341.907C109.719,-330.652 101.04,-318.418 93.0155,-307.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"95.6693,-304.798 87.0287,-298.667 89.96,-308.848 95.6693,-304.798\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#a06aec\" stroke=\"black\" d=\"M302,-306C302,-306 157,-306 157,-306 151,-306 145,-300 145,-294 145,-294 145,-235 145,-235 145,-229 151,-223 157,-223 157,-223 302,-223 302,-223 308,-223 314,-229 314,-235 314,-235 314,-294 314,-294 314,-300 308,-306 302,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"153\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) ≤ 6.05</text>\r\n",
       "<text text-anchor=\"start\" x=\"196\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\r\n",
       "<text text-anchor=\"start\" x=\"190\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"start\" x=\"181\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 4]</text>\r\n",
       "<text text-anchor=\"start\" x=\"179.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M175.296,-341.907C181.606,-333.014 188.348,-323.509 194.859,-314.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"197.823,-316.202 200.754,-306.021 192.114,-312.152 197.823,-316.202\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M219,-187C219,-187 84,-187 84,-187 78,-187 72,-181 72,-175 72,-175 72,-116 72,-116 72,-110 78,-104 84,-104 84,-104 219,-104 219,-104 225,-104 231,-110 231,-116 231,-116 231,-175 231,-175 231,-181 225,-187 219,-187\"/>\r\n",
       "<text text-anchor=\"start\" x=\"80\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.55</text>\r\n",
       "<text text-anchor=\"start\" x=\"122.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"112\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"start\" x=\"103\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"96\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.438,-222.907C196.57,-214.105 190.302,-204.703 184.241,-195.612\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"186.973,-193.4 178.514,-187.021 181.149,-197.283 186.973,-193.4\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M353.5,-179.5C353.5,-179.5 261.5,-179.5 261.5,-179.5 255.5,-179.5 249.5,-173.5 249.5,-167.5 249.5,-167.5 249.5,-123.5 249.5,-123.5 249.5,-117.5 255.5,-111.5 261.5,-111.5 261.5,-111.5 353.5,-111.5 353.5,-111.5 359.5,-111.5 365.5,-117.5 365.5,-123.5 365.5,-123.5 365.5,-167.5 365.5,-167.5 365.5,-173.5 359.5,-179.5 353.5,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"278.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"268\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"start\" x=\"259\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\r\n",
       "<text text-anchor=\"start\" x=\"257.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>5&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M256.562,-222.907C264.065,-211.652 272.221,-199.418 279.763,-188.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.754,-189.929 285.389,-179.667 276.929,-186.046 282.754,-189.929\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M127.5,-68C127.5,-68 35.5,-68 35.5,-68 29.5,-68 23.5,-62 23.5,-56 23.5,-56 23.5,-12 23.5,-12 23.5,-6 29.5,-0 35.5,-0 35.5,-0 127.5,-0 127.5,-0 133.5,-0 139.5,-6 139.5,-12 139.5,-12 139.5,-56 139.5,-56 139.5,-62 133.5,-68 127.5,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"52.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"42\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"start\" x=\"33\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"31.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>6&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125.435,-103.726C119.837,-94.9703 113.913,-85.7032 108.289,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"111.123,-74.8399 102.787,-68.2996 105.225,-78.6103 111.123,-74.8399\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M273,-68C273,-68 170,-68 170,-68 164,-68 158,-62 158,-56 158,-56 158,-12 158,-12 158,-6 164,-0 170,-0 170,-0 273,-0 273,-0 279,-0 285,-6 285,-12 285,-12 285,-56 285,-56 285,-62 279,-68 273,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"192.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"182\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"166\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>6&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177.565,-103.726C183.163,-94.9703 189.087,-85.7032 194.711,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"197.775,-78.6103 200.213,-68.2996 191.877,-74.8399 197.775,-78.6103\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1e2d550de48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "\n",
    "There are many other classifiers available in scikit-learn that one might use. Below we'll use a k-nearest neighbors classifier. \n",
    "\n",
    "  * **See:** http://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "built-in accuracy calculation (knn): 0.96\n",
      "built-in accuracy calculation (dtree): 0.96\n",
      "built-in accuracy calculation (dtree), v2: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(iris_x_train, iris_y_train) \n",
    "print(\"built-in accuracy calculation (knn):\", accuracy_score(knn.predict(iris_x_test), iris_y_test))\n",
    "\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree.fit(iris_x_train, iris_y_train) \n",
    "print(\"built-in accuracy calculation (dtree):\", accuracy_score(dtree.predict(iris_x_test), iris_y_test))\n",
    "print(\"built-in accuracy calculation (dtree), v2:\", dtree.score(iris_x_test, iris_y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Scikit-learn also defines multiple classes for regression. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes data set shape:  (442, 10)\n"
     ]
    }
   ],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "print(\"Diabetes data set shape: \",diabetes.data.shape)\n",
    "diabetes_X_train = diabetes.data[:-20]\n",
    "diabetes_X_test  = diabetes.data[-20:]\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test  = diabetes.target[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orindary Least Squares Linear Regression\n",
    "\n",
    "*  **See:** http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients:\n",
      " [ 3.03499549e-01 -2.37639315e+02  5.10530605e+02  3.27736980e+02\n",
      " -8.14131709e+02  4.92814588e+02  1.02848452e+02  1.84606489e+02\n",
      "  7.43519617e+02  7.60951722e+01]\n",
      "calculated error on test set: 2004.5676026898211\n",
      "built-in error on test set 1: 2004.5676026898211\n",
      "built-in error on test set 2: 0.5850753022690574\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "# fit the data\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# print out the linear model\n",
    "print(\"coefficients:\\n\", regr.coef_)\n",
    "\n",
    "#compute predicted values on test test;\n",
    "predicted = regr.predict(diabetes_X_test);\n",
    "\n",
    "# The mean squared error\n",
    "err = np.mean((regr.predict(diabetes_X_test)-diabetes_y_test)**2)\n",
    "print(\"calculated error on test set:\",err)\n",
    "# compare result to builtin mse\n",
    "print(\"built-in error on test set 1:\", metrics.mean_squared_error(diabetes_y_test,predicted))\n",
    "print(\"built-in error on test set 2:\",regr.score(diabetes_X_test, diabetes_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other linear models:\n",
    "* **See:** http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "coefficients:\n",
      " [  34.27253573  -80.06235273  296.73036586  199.14438365    6.14639012\n",
      "  -26.10294287 -150.21661191  119.4044712   254.49896275  115.68515613]\n",
      "calculated error on test set: 2693.3680421776858\n",
      "built-in error on test set: 2693.3680421776858\n",
      "--------------------------------------------------\n",
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "coefficients:\n",
      " [  0.          -0.         357.61234402  11.57097751   0.\n",
      "   0.          -0.           0.         305.62172841   0.        ]\n",
      "calculated error on test set: 3037.2580917088812\n",
      "built-in error on test set: 3037.2580917088812\n",
      "--------------------------------------------------\n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "coefficients:\n",
      " [[-0.01991321 -0.14600187 -0.15115461 ... -0.13172782 -0.06036694\n",
      "  -0.09833287]\n",
      " [ 0.10359309 -0.14600187  0.21745712 ... -0.07120998 -0.22787308\n",
      "  -0.16874869]\n",
      " [ 0.00551455 -0.14600187 -0.37857296 ... -0.2892956  -0.20010437\n",
      "  -0.24330661]\n",
      " ...\n",
      " [ 0.13991848  0.3306069   0.54187855 ... -0.09740978  0.07507458\n",
      "   0.45256735]\n",
      " [ 0.16171371  0.3306069   0.58930229 ...  0.44725077 -0.09584993\n",
      "  -0.00306441]\n",
      " [-0.23786552 -0.24132363  0.75528535 ...  0.18525281  0.15835714\n",
      "   0.0052198 ]]\n",
      "calculated error on test set: 16237.4\n",
      "built-in error on test set: 16237.4\n"
     ]
    }
   ],
   "source": [
    "ridge_regr = linear_model.Ridge()\n",
    "lasso_regr = linear_model.Lasso()\n",
    "perceptron = linear_model.Perceptron()\n",
    "for regr in [ridge_regr, lasso_regr,perceptron]:\n",
    "    print('-'*50)\n",
    "    print(regr)\n",
    "    # fit the data\n",
    "    regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "    # print out the linear model\n",
    "    print(\"coefficients:\\n\", regr.coef_)\n",
    "    #compute predicted values on test test;\n",
    "    predicted = regr.predict(diabetes_X_test);\n",
    "    # The mean squared error\n",
    "    err = np.mean((regr.predict(diabetes_X_test)-diabetes_y_test)**2)\n",
    "    print(\"calculated error on test set:\",err)\n",
    "    # compare result to builtin mse\n",
    "    print(\"built-in error on test set:\", metrics.mean_squared_error(diabetes_y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "With both of the data sets above, we split the data into training and testing sets. The first is used to develop the model, and the second is used to develop it. \n",
    "\n",
    "Another technique for separating the datasets is **k-fold cross-validation**. Here, the data is split into $k$ folds, and the machine learning algorithm is run for $k$ iterations. In each iteration, $k-1$ folds are used to train the data, and the remaining one is ued to test. A score is calculated and stored for each fold. The performance of the algorithm is taken to be the average score over all of the iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "[15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "[45 46 47 48 49 50 51 52 53 54 55 56 57 58 59]\n",
      "[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74]\n",
      "[75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]\n",
      "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104]\n",
      "[105 106 107 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134]\n",
      "[135 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data[indices]\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "for train_indices, test_indices in k_fold.split(data):\n",
    "    print(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets:   [0 2 0 2 1 2 0 1 1 1 2 1 2 0 1]\n",
      "precicted: [0 2 0 2 1 2 0 1 1 1 2 1 2 0 1]\n",
      "accuracy 1.0\n",
      "---------\n",
      "targets:   [0 0 2 1 2 0 1 0 1 1 0 0 1 0 1]\n",
      "precicted: [0 0 2 1 2 0 2 0 1 1 0 0 1 0 1]\n",
      "accuracy 0.9333333333333333\n",
      "---------\n",
      "targets:   [1 2 2 1 2 2 1 0 1 2 2 2 2 1 2]\n",
      "precicted: [1 2 2 1 2 2 1 0 1 1 2 2 2 1 2]\n",
      "accuracy 0.9333333333333333\n",
      "---------\n",
      "targets:   [0 2 0 2 1 1 2 0 0 2 0 1 2 1 0]\n",
      "precicted: [0 2 0 1 1 1 2 0 0 2 0 1 2 1 0]\n",
      "accuracy 0.9333333333333333\n",
      "---------\n",
      "targets:   [2 0 0 2 1 0 1 1 1 2 2 1 2 2 1]\n",
      "precicted: [2 0 0 2 1 0 1 1 2 2 2 1 2 1 1]\n",
      "accuracy 0.8666666666666667\n",
      "---------\n",
      "targets:   [2 1 0 0 2 2 0 2 0 0 1 1 0 2 0]\n",
      "precicted: [2 1 0 0 2 2 0 2 0 0 1 1 0 2 0]\n",
      "accuracy 1.0\n",
      "---------\n",
      "targets:   [0 0 0 2 0 1 2 0 0 1 1 2 2 0 2]\n",
      "precicted: [0 0 0 1 0 1 1 0 0 1 1 2 2 0 2]\n",
      "accuracy 0.8666666666666667\n",
      "---------\n",
      "targets:   [1 0 1 2 2 1 0 1 0 1 2 0 0 2 1]\n",
      "precicted: [1 0 1 2 2 1 0 1 0 1 2 0 0 2 1]\n",
      "accuracy 1.0\n",
      "---------\n",
      "targets:   [0 0 0 1 0 1 1 0 0 1 2 2 1 2 2]\n",
      "precicted: [0 0 0 1 0 1 1 0 0 2 2 2 2 2 2]\n",
      "accuracy 0.8666666666666667\n",
      "---------\n",
      "targets:   [2 0 2 0 1 2 2 1 2 0 1 0 1 1 1]\n",
      "precicted: [2 0 2 0 1 2 2 1 2 0 1 0 1 1 1]\n",
      "accuracy 1.0\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import  mean_squared_error as mse\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = datasets.load_iris()\n",
    "indices = np.random.permutation(len(iris.data))\n",
    "\n",
    "data = iris.data[indices]\n",
    "target = iris.target[indices]\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "for train_indices, test_indices in k_fold.split(data):\n",
    "    clf.fit(data[train_indices], target[train_indices]) \n",
    "    predicted = clf.predict(data[test_indices])\n",
    "    clf.score\n",
    "    print(\"targets:  \", target[test_indices])\n",
    "    print(\"precicted:\", predicted)\n",
    "    print(\"accuracy\", accuracy_score(target[test_indices], predicted))\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have manually iterated over the folds. There are more compact ways of using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         0.93333333 0.93333333 0.86666667\n",
      " 0.93333333 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "print(cross_val_score(dtree, iris.data, iris.target,cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         0.93333333 0.93333333 0.86666667\n",
      " 1.         0.86666667 0.73333333 1.        ]\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=10)\n",
    "cross_val_score(dtree, iris.data, iris.target,cv=k_fold)\n",
    "print(cross_val_score(dtree, iris.data, iris.target,cv=k_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas\n",
    "\n",
    "It's also possible to use Pandas DataFrames with scikit-learn. Below, we read in the iris dataset from a csv file, permute the data, and then split it into training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances where predicted (left) and actual (right) differ.\n",
      "33 Iris-virginica Iris-versicolor\n",
      "41 Iris-virginica Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.tree as tree\n",
    "\n",
    "# read in the data\n",
    "file = '..\\\\data-sets\\\\iris.csv'\n",
    "train = pd.read_csv(file)\n",
    "\n",
    "#extract input and targets\n",
    "input_attributes = ['sepallength','sepalwidth','petallength','petalwidth']\n",
    "data = train.loc[:, input_attributes]\n",
    "y = train.TargetClass\n",
    "\n",
    "\n",
    "# permute the data and create training and testing sets.\n",
    "np.random.seed(0)\n",
    "offset = -50\n",
    "indices = np.random.permutation(len(data))\n",
    "data_train = data.iloc[indices[:offset]]\n",
    "y_train = y.iloc[indices[:offset]]\n",
    "data_test  = data.iloc[indices[offset:]]\n",
    "y_test  = y.iloc[indices[offset:]]\n",
    "\n",
    "# create an estimator and fit it.\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree.fit(data_train, y_train) \n",
    "\n",
    "# print out some results\n",
    "results = dtree.predict(data_test)\n",
    "print('Instances where predicted (left) and actual (right) differ.')\n",
    "for i in range(len(results)):\n",
    "    if results[i] != y_test.iloc[i]:\n",
    "        print(i, results[i],y_test.iloc[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python_defaultSpec_1599662491784"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}