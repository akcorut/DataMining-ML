{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptrons\n",
    "\n",
    "Two standard neural network estimators defined in `scikit-learn` are `MLPClassifier` and `MLPRegressor`.\n",
    "\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
    "\n",
    "We'll demonstrate how to use both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np;\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "### Read in a data set\n",
    "\n",
    "We'll again use the Wisconsin breast cancer data set. The target is binary: 0 (M) and 1 (B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:\t (569, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radiusAvg</th>\n",
       "      <th>textureAvg</th>\n",
       "      <th>perimeterAvg</th>\n",
       "      <th>areaAvg</th>\n",
       "      <th>smoothnessAvg</th>\n",
       "      <th>compactnessAvg</th>\n",
       "      <th>concavityAvg</th>\n",
       "      <th>concavepointsAvg</th>\n",
       "      <th>symmetryAvg</th>\n",
       "      <th>...</th>\n",
       "      <th>textureWorst</th>\n",
       "      <th>perimeterWorst</th>\n",
       "      <th>areaWorst</th>\n",
       "      <th>smoothnessWorst</th>\n",
       "      <th>compactnessWorst</th>\n",
       "      <th>concavityWorst</th>\n",
       "      <th>concavepointsWorst</th>\n",
       "      <th>symmetryWorst</th>\n",
       "      <th>fractaldimWorst</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  radiusAvg  textureAvg  perimeterAvg  areaAvg  smoothnessAvg  \\\n",
       "0    842302      17.99       10.38        122.80   1001.0        0.11840   \n",
       "1    842517      20.57       17.77        132.90   1326.0        0.08474   \n",
       "2  84300903      19.69       21.25        130.00   1203.0        0.10960   \n",
       "3  84348301      11.42       20.38         77.58    386.1        0.14250   \n",
       "4  84358402      20.29       14.34        135.10   1297.0        0.10030   \n",
       "\n",
       "   compactnessAvg  concavityAvg  concavepointsAvg  symmetryAvg  ...  \\\n",
       "0         0.27760        0.3001           0.14710       0.2419  ...   \n",
       "1         0.07864        0.0869           0.07017       0.1812  ...   \n",
       "2         0.15990        0.1974           0.12790       0.2069  ...   \n",
       "3         0.28390        0.2414           0.10520       0.2597  ...   \n",
       "4         0.13280        0.1980           0.10430       0.1809  ...   \n",
       "\n",
       "   textureWorst  perimeterWorst  areaWorst  smoothnessWorst  compactnessWorst  \\\n",
       "0         17.33          184.60     2019.0           0.1622            0.6656   \n",
       "1         23.41          158.80     1956.0           0.1238            0.1866   \n",
       "2         25.53          152.50     1709.0           0.1444            0.4245   \n",
       "3         26.50           98.87      567.7           0.2098            0.8663   \n",
       "4         16.67          152.20     1575.0           0.1374            0.2050   \n",
       "\n",
       "   concavityWorst  concavepointsWorst  symmetryWorst  fractaldimWorst  c  \n",
       "0          0.7119              0.2654         0.4601          0.11890  0  \n",
       "1          0.2416              0.1860         0.2750          0.08902  0  \n",
       "2          0.4504              0.2430         0.3613          0.08758  0  \n",
       "3          0.6869              0.2575         0.6638          0.17300  0  \n",
       "4          0.4000              0.1625         0.2364          0.07678  0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in a data set using Pandas. \n",
    "wdbc_data = '../data-sets/wdbc.csv'\n",
    "df = pd.read_csv(wdbc_data, header=0)\n",
    "print(\"shape:\\t\",df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data\n",
    "\n",
    "Neural networks are sensitive to scaling, and so we scale the data (in this case using a min-max scaler). We then create a training testing split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 398\n",
      "Testing set size: 171\n",
      "Input attributes: 30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = df.iloc[:].values\n",
    "\n",
    "test_percent = 0.3\n",
    "\n",
    "# extract X and y values from the data set; \n",
    "X = data[:, 1:-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# use a min max scaler to put the features in [0,1]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)            \n",
    "\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=test_percent, shuffle=True)\n",
    "\n",
    "print(\"Training set size:\", len(y_train))\n",
    "print(\"Testing set size:\", len(y_test))\n",
    "print(\"Input attributes:\",X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, `B` is 1 and `M` is 0. \n",
    "\n",
    "## Creating an `MLPClassifier`\n",
    "\n",
    "Below we create three different classifiers, each based on a different learning algorithm (`lbfgs`, `sdg`, `adam`), including stochastic gradient descent. We also specify that the learning rate is constant.\n",
    "\n",
    "In general, there are many parameters that can be set for the neural network (importantly, the number of hidden layers and the number of nodes in each). We've left the defaults in place, but understand that these values can wildly affect the final results. \n",
    "\n",
    "We've set the maximum number of iteratios (epochs) to 5000. In some cases, the network will fail to converge (this will generate a warning message). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tB\tM\n",
      "B\t98\t2\n",
      "M\t2\t69\n",
      "--------------------\n",
      "accuracy: 0.9766081871345029\n",
      "\tB\tM\n",
      "B\t98\t2\n",
      "M\t3\t68\n",
      "--------------------\n",
      "accuracy: 0.9707602339181286\n",
      "\tB\tM\n",
      "B\t98\t2\n",
      "M\t3\t68\n",
      "--------------------\n",
      "accuracy: 0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf1 = MLPClassifier(solver='lbfgs',max_iter=5000,activation='logistic', learning_rate  = 'constant')\n",
    "clf2 = MLPClassifier(solver='sgd',max_iter=5000, learning_rate  = 'constant')\n",
    "clf3 = MLPClassifier(solver='adam',max_iter=5000, learning_rate  = 'constant')\n",
    "\n",
    "for clf in [clf1,clf2,clf3]:\n",
    "    clf.fit(X_train, y_train)                         \n",
    "    predicted= np.array(clf.predict(X_test))\n",
    "    cm = metrics.confusion_matrix(y_test, predicted,labels=[1,0])\n",
    "    print(\"\",\"B\",\"M\",sep=\"\\t\")\n",
    "    print(\"B\",cm[0,0],cm[0,1],sep=\"\\t\" )\n",
    "    print(\"M\",cm[1,0],cm[1,1],sep=\"\\t\" )\n",
    "    print('-'*20)\n",
    "    print(\"accuracy:\", metrics.accuracy_score(predicted,y_test))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we examine which instances the first classifier got incorrect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 1.0 X\n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 0.0 X\n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 0.0 X\n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 1.0 X\n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n",
      "0.0 0.0 \n",
      "1.0 1.0 \n"
     ]
    }
   ],
   "source": [
    "for pred,yact in zip(clf1.predict(X_test),y_test):\n",
    "    s = \"\"\n",
    "    if not pred==yact:\n",
    "        s = \"X\"\n",
    "    print(pred,yact, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilities\n",
    "\n",
    "It's also possible to output probabilities using `predict_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|0.992\t0.008|\t0.0\t\n",
      "1.0\t|0.001\t0.999|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.245\t0.755|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.003\t0.997|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|0.998\t0.002|\t1.0\tX\n",
      "1.0\t|0.272\t0.728|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.015\t0.985|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t0.0\tX\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.026\t0.974|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.004\t0.996|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t0.0\tX\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.103\t0.897|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t1.0\tX\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.057\t0.943|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.001\t0.999|\t1.0\t\n",
      "0.0\t|1.000\t0.000|\t0.0\t\n",
      "1.0\t|0.000\t1.000|\t1.0\t\n"
     ]
    }
   ],
   "source": [
    "for pred, pred_class, yact in zip(clf1.predict_proba(X_test),clf1.predict(X_test), y_test):\n",
    "    s = \"\"\n",
    "    if not pred_class==yact:\n",
    "        s = \"X\"    \n",
    "    print(f\"{pred_class}\\t|{pred[0]:.3f}\\t{pred[1]:.3f}|\\t{yact}\\t{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers\n",
    "\n",
    "By default, a single hidden layer of 100 nodes is used. Other architectures can be specified using `hidden_layer_sizes`. E.g., `hidden_layer_sizes=(60, 30)`.\n",
    "\n",
    "We can gain access to the coefficients of the edges, including those due to bias nodes, using `coefs_` and `intercepts_`, respectively. `coefs_` is a list of coefficient matrices. The first element of the list contains all of weights for edges from the input nodes to the first hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: (30, 100)\n",
      "layer: (100, 1)\n",
      "bias,layer: (100,)\n",
      "bias,layer: (1,)\n",
      "[array([ 5.55732722e-01, -1.86291089e+00, -7.40773677e-01, -1.40741144e+00,\n",
      "        3.92775351e+00,  1.84177935e-01, -2.27588988e+00,  1.13133656e+00,\n",
      "        2.10994809e-02, -3.28884477e+00,  3.90780066e-01, -4.16553872e-01,\n",
      "       -5.92917996e-01, -6.19594596e-01,  8.17678671e-01,  1.93641559e+00,\n",
      "        9.59328352e-02,  2.16567048e+00, -1.39443028e+00,  3.52184437e+00,\n",
      "        1.82742490e-01, -2.74407875e-01, -6.00911393e-01, -3.55036345e-01,\n",
      "        1.70782032e-01,  4.22614640e-01, -3.13074786e-01,  9.98684192e-01,\n",
      "       -2.14849938e+00, -1.12935592e+00,  2.40971967e-01, -5.58628482e-01,\n",
      "       -2.01594718e+00, -4.90632372e-01, -1.12171924e-02,  5.80011559e-01,\n",
      "        1.25983538e-01,  1.00224592e+00,  5.11345490e+00,  4.55162799e-01,\n",
      "       -1.11989294e+00, -1.75085479e-01,  1.32536149e-01, -7.34204698e-02,\n",
      "       -1.05832467e+00,  2.20146077e-01,  8.43884766e-03,  2.24236005e-02,\n",
      "        6.63696477e+00,  4.06468671e-01,  5.29682047e-03, -1.31233696e+00,\n",
      "        2.42282035e-01,  4.21173807e-01, -1.13135499e+00,  5.91992997e-01,\n",
      "       -1.58796235e-01,  1.12124063e+00,  4.58920459e-01,  1.34077552e+00,\n",
      "        7.60271330e-01,  3.37555385e-01,  6.96519054e+00, -8.23748922e-01,\n",
      "       -2.78055784e+00, -3.03457343e-02,  9.06780493e-02, -3.33289306e+00,\n",
      "        3.42374976e-01, -6.60430583e-01, -9.53564935e-01, -5.98212691e-01,\n",
      "        6.33866532e-01, -1.40171699e+00, -6.42983884e-01,  7.42352708e-01,\n",
      "       -3.03151968e-02, -8.99590284e-01, -7.11647071e-01,  1.83817582e+00,\n",
      "       -1.06821238e-01,  1.41279797e-01,  8.22948041e+00,  2.28238726e+00,\n",
      "       -7.61792859e-01, -2.24370805e+00, -6.22080042e-01, -1.32079441e+00,\n",
      "       -2.80209540e+00, -3.17532457e-01,  3.67333637e+00,  3.37205017e-01,\n",
      "        1.56992328e+00,  2.93003518e+00, -4.19660781e+00,  9.44359898e-01,\n",
      "       -1.46654624e-01,  7.78906112e-02,  8.42088358e-01, -2.81063071e+00]), array([-0.94908108])]\n"
     ]
    }
   ],
   "source": [
    "# shape of coefficient arrays, by layer; \n",
    "for c in clf1.coefs_:\n",
    "    print(\"layer:\", c.shape)\n",
    "    \n",
    "# bias node coefficients\n",
    "for b in clf1.intercepts_:\n",
    "    print(\"bias,layer:\", b.shape)\n",
    "    \n",
    "print(clf1.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create anothe network with  2 hidden layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tB\tM\n",
      "B\t98\t2\n",
      "M\t1\t70\n",
      "--------------------------------------------------------------------------------\n",
      "accuracy: 0.9824561403508771\n",
      "--------------------------------------------------------------------------------\n",
      "layer: (30, 60)\n",
      "layer: (60, 30)\n",
      "layer: (30, 1)\n",
      "--------------------------------------------------------------------------------\n",
      "bias,layer: (60,)\n",
      "bias,layer: (30,)\n",
      "bias,layer: (1,)\n"
     ]
    }
   ],
   "source": [
    "clf4 = MLPClassifier(solver='sgd',max_iter=5000, learning_rate  = 'constant', hidden_layer_sizes=(60,30))\n",
    "clf4.fit(X_train, y_train)                         \n",
    "predicted= np.array(clf4.predict(X_test))\n",
    "cm = metrics.confusion_matrix(y_test, predicted,labels=[1,0])\n",
    "print(\"\",\"B\",\"M\",sep=\"\\t\")\n",
    "print(\"B\",cm[0,0],cm[0,1],sep=\"\\t\" )\n",
    "print(\"M\",cm[1,0],cm[1,1],sep=\"\\t\" )\n",
    "print('-'*80)\n",
    "print(\"accuracy:\", metrics.accuracy_score(predicted,y_test))   \n",
    "print('-'*80)\n",
    "# shape of coefficient arrays, by layer; \n",
    "for c in clf4.coefs_:\n",
    "    print(\"layer:\", c.shape)\n",
    "print('-'*80)    \n",
    "# bias node coefficients\n",
    "for b in clf4.intercepts_:\n",
    "    print(\"bias,layer:\", b.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "To search for ideal parameters, we can use a grid search, which makes use of a dictionary of parameters and allowable values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.975401 {'activation': 'logistic', 'solver': 'adam'}\n",
      "--------------------------------------------------------------------------------\n",
      "0.9491\t{'activation': 'identity', 'solver': 'lbfgs'}\n",
      "0.9455\t{'activation': 'identity', 'solver': 'sgd'}\n",
      "0.9719\t{'activation': 'identity', 'solver': 'adam'}\n",
      "0.9578\t{'activation': 'logistic', 'solver': 'lbfgs'}\n",
      "0.6274\t{'activation': 'logistic', 'solver': 'sgd'}\n",
      "0.9754\t{'activation': 'logistic', 'solver': 'adam'}\n",
      "0.9596\t{'activation': 'tanh', 'solver': 'lbfgs'}\n",
      "0.9455\t{'activation': 'tanh', 'solver': 'sgd'}\n",
      "0.9719\t{'activation': 'tanh', 'solver': 'adam'}\n",
      "0.9649\t{'activation': 'relu', 'solver': 'lbfgs'}\n",
      "0.9403\t{'activation': 'relu', 'solver': 'sgd'}\n",
      "0.9754\t{'activation': 'relu', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'solver' : ['lbfgs','sgd','adam'],\n",
    "    'activation' : ['identity', 'logistic', 'tanh', 'relu']\n",
    "    }\n",
    "    \n",
    "clf = MLPClassifier(max_iter=1000, learning_rate  = 'constant', random_state=1)\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, cv = 3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "print(\"best score: %f %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print('-'*80)\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"{:.4f}\\t{}\".format(mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classification\n",
    "\n",
    "It is possible to use `MLPClassifier` in multiclass classification problems. Below, we use the Iris data set, which consists of 3 classes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2==2\t[2]\tTrue\t0=1.0326e-06\t1=0.0023\t2=1.0\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.00077084\t1=0.99\t2=0.011\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.99973\t1=0.00027\t2=1.1e-11\t1.00\n",
      "2==2\t[2]\tTrue\t0=1.202e-05\t1=0.013\t2=0.99\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.99998\t1=2.3e-05\t2=1.3e-13\t1.00\n",
      "2==2\t[2]\tTrue\t0=4.3226e-06\t1=0.0076\t2=0.99\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.0015509\t1=0.99\t2=0.0054\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.0010816\t1=1.0\t2=0.0024\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.00083857\t1=0.95\t2=0.047\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.0015024\t1=0.96\t2=0.04\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.0013455\t1=1.0\t2=0.0023\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.99926\t1=0.00074\t2=7e-11\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.99986\t1=0.00014\t2=3.1e-12\t1.00\n",
      "2==2\t[2]\tTrue\t0=1.7693e-06\t1=0.011\t2=0.99\t1.00\n",
      "2==2\t[2]\tTrue\t0=2.6623e-05\t1=0.065\t2=0.93\t1.00\n",
      "2==2\t[2]\tTrue\t0=6.359e-06\t1=0.016\t2=0.98\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.99909\t1=0.00091\t2=1.2e-10\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.0016301\t1=0.99\t2=0.0071\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.99989\t1=0.00011\t2=2.8e-12\t1.00\n",
      "2==2\t[2]\tTrue\t0=3.0921e-06\t1=0.0044\t2=1.0\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.99978\t1=0.00022\t2=9.5e-12\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.0011549\t1=0.66\t2=0.34\t1.00\n",
      "2==2\t[2]\tTrue\t0=2.1707e-06\t1=0.02\t2=0.98\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.0014369\t1=1.0\t2=0.0028\t1.00\n",
      "2==2\t[2]\tTrue\t0=8.997e-06\t1=0.029\t2=0.97\t1.00\n",
      "2==2\t[2]\tTrue\t0=7.0738e-07\t1=0.0085\t2=0.99\t1.00\n",
      "2==2\t[2]\tTrue\t0=5.3741e-05\t1=0.071\t2=0.93\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.99997\t1=2.9e-05\t2=7.1e-13\t1.00\n",
      "2==2\t[2]\tTrue\t0=1.0949e-05\t1=0.03\t2=0.97\t1.00\n",
      "2==2\t[2]\tTrue\t0=3.4405e-05\t1=0.087\t2=0.91\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.00060738\t1=1.0\t2=0.0035\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.9999\t1=9.8e-05\t2=1e-12\t1.00\n",
      "2==2\t[2]\tTrue\t0=8.1872e-06\t1=0.012\t2=0.99\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.0011437\t1=0.78\t2=0.21\t1.00\n",
      "2==2\t[2]\tTrue\t0=1.4923e-06\t1=0.0068\t2=0.99\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.0018603\t1=1.0\t2=0.0021\t1.00\n",
      "2==2\t[2]\tTrue\t0=5.3547e-07\t1=0.002\t2=1.0\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.00076378\t1=0.95\t2=0.054\t1.00\n",
      "2==2\t[2]\tTrue\t0=5.3333e-07\t1=0.0017\t2=1.0\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.00073894\t1=1.0\t2=0.003\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.99979\t1=0.00021\t2=2.3e-12\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.0012777\t1=0.93\t2=0.072\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.9998\t1=0.0002\t2=2.4e-11\t1.00\n",
      "0==0\t[0]\tTrue\t0=0.99972\t1=0.00028\t2=1e-11\t1.00\n",
      "1==1\t[1]\tTrue\t0=0.0007301\t1=0.96\t2=0.043\t1.00\n",
      "--------------------------------------------------------------------------------\n",
      "layer: (4, 100)\n",
      "layer: (100, 3)\n",
      "--------------------------------------------------------------------------------\n",
      "bias,layer: (100,)\n",
      "bias,layer: (3,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris_x = iris.data\n",
    "iris_y = iris.target\n",
    "X_train, X_test, y_train, y_test =  train_test_split(iris_x, iris_y, test_size=test_percent, shuffle=True)\n",
    "\n",
    "iris_mlp = MLPClassifier(max_iter=1000)\n",
    "iris_mlp.fit(X_train, y_train) \n",
    "iris_mlp.predict(X_test)\n",
    "\n",
    "for p,c, a in zip(iris_mlp.predict_proba(X_test),iris_mlp.predict(X_test),y_test):\n",
    "    print(\"{}=={}\\t[{}]\\t{}\\t0={:0.5}\\t1={:0.2}\\t2={:0.2}\\t{:.2f}\".format(a,np.argmax(p), c,a == np.argmax(p),p[0],p[1],p[2],np.sum(p)))\n",
    "    \n",
    "print('-'*80)   \n",
    "# shape of coefficient arrays, by layer; \n",
    "for c in iris_mlp.coefs_:\n",
    "    print(\"layer:\", c.shape)\n",
    "print('-'*80)    \n",
    "# bias node coefficients\n",
    "for b in iris_mlp.intercepts_:\n",
    "    print(\"bias,layer:\", b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "`MLPRegressor` can be used in regression problems. \n",
    "\n",
    "Below, we use the builtin Boston housing prices data set. We only use a select number of its input attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import  mean_squared_error as mse\n",
    "boston = load_boston()\n",
    "X = boston.data[:,[0,1,2,4,5,6,7,10,11,12]] \n",
    "y = boston.target\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN:  5.0\n",
      "MAX:  50.0\n",
      "MEAN:  22.532806324110677\n",
      "STD:  9.188011545278203\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # pyplot is gives a matlab like feel. \n",
    "# need the below for presenting plots in Jupyiter notebook. \n",
    "%matplotlib inline  \n",
    "print(\"MIN: \", np.min(y))\n",
    "print(\"MAX: \", np.max(y))\n",
    "print(\"MEAN: \", np.mean(y))\n",
    "print(\"STD: \", np.std(y))\n",
    "plt.hist(y)\n",
    "plt.show()\n",
    "plt.boxplot(y)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again scale the data using a min-max scaler, which will put the attribute values in [0,1]. We then compare two models, noe  created with the unscaled data and another created with the scaled data. \n",
    "\n",
    "Bewow, use use the mean-squared-error to compare the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nimda\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 14.911\t8.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nimda\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 16.239\t10.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nimda\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 6.292\t8.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nimda\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 36.583\t25.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nimda\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 33.357\t23.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nimda\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 35.631\t16.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nimda\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 20.391\t9.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nimda\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 93.244\t154.123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nimda\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 70.620\t27.553\n",
      "mse 20.942\t13.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nimda\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "Xscaled = min_max_scaler.fit_transform(X)   \n",
    "cvk = KFold(n_splits=10)\n",
    "scores = []\n",
    "for train_indices, test_indices in cvk.split(y):\n",
    "    reg = MLPRegressor(max_iter=1000)    \n",
    "    reg.fit(X[train_indices],y[train_indices])\n",
    "    predicted = reg.predict(X[test_indices])\n",
    "    reg = MLPRegressor(max_iter=1000)    \n",
    "    reg.fit(Xscaled[train_indices],y[train_indices])\n",
    "    predicted2 = reg.predict(Xscaled[test_indices])\n",
    "    print(\"mse {:.3f}\\t{:.3f}\".format(mse(y[test_indices], predicted),mse(y[test_indices], predicted2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we split the data into training and testing sets, create a model, and compare the predicted value to the actual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 11.627\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.6633\t5.6000\n",
      "9.0541\t7.2000\n",
      "12.0416\t7.5000\n",
      "13.5180\t8.3000\n",
      "10.4373\t8.8000\n",
      "14.4149\t9.5000\n",
      "12.0687\t10.2000\n",
      "12.5111\t10.4000\n",
      "3.6964\t10.4000\n",
      "14.0706\t10.8000\n",
      "13.6411\t11.0000\n",
      "13.5484\t11.5000\n",
      "12.4173\t12.3000\n",
      "15.7691\t12.5000\n",
      "12.6301\t12.7000\n",
      "16.1718\t12.7000\n",
      "15.0614\t13.0000\n",
      "16.6585\t13.1000\n",
      "12.2700\t13.4000\n",
      "13.5330\t13.4000\n",
      "11.4362\t13.5000\n",
      "15.6043\t13.5000\n",
      "7.8837\t13.8000\n",
      "9.8243\t13.8000\n",
      "14.6782\t14.0000\n",
      "17.5468\t14.1000\n",
      "17.0656\t14.5000\n",
      "15.3825\t14.9000\n",
      "17.0777\t15.3000\n",
      "13.3853\t15.6000\n",
      "16.8630\t15.6000\n",
      "18.5685\t16.1000\n",
      "16.3000\t16.6000\n",
      "20.0992\t16.8000\n",
      "19.8086\t17.1000\n",
      "18.2970\t17.2000\n",
      "15.0205\t17.3000\n",
      "17.3906\t17.6000\n",
      "18.5894\t17.7000\n",
      "14.1555\t17.8000\n",
      "17.2681\t18.0000\n",
      "17.5815\t18.2000\n",
      "16.3281\t18.4000\n",
      "23.2803\t18.5000\n",
      "18.5445\t18.6000\n",
      "17.0449\t18.8000\n",
      "21.4756\t19.0000\n",
      "14.4757\t19.0000\n",
      "20.6295\t19.4000\n",
      "16.7095\t19.4000\n",
      "21.3628\t19.4000\n",
      "16.9312\t19.5000\n",
      "20.3243\t19.6000\n",
      "17.9672\t19.6000\n",
      "20.4914\t19.7000\n",
      "21.4603\t20.0000\n",
      "16.1703\t20.0000\n",
      "19.8833\t20.1000\n",
      "18.5845\t20.1000\n",
      "19.2018\t20.1000\n",
      "18.6173\t20.3000\n",
      "22.3384\t20.4000\n",
      "21.8709\t20.7000\n",
      "19.8689\t21.0000\n",
      "22.0579\t21.0000\n",
      "22.3741\t21.0000\n",
      "21.5533\t21.1000\n",
      "21.4579\t21.2000\n",
      "19.8542\t21.4000\n",
      "20.0588\t21.4000\n",
      "17.3558\t21.5000\n",
      "19.9021\t21.5000\n",
      "22.4629\t21.6000\n",
      "18.3794\t21.7000\n",
      "18.3367\t21.7000\n",
      "19.0875\t22.0000\n",
      "25.6524\t22.0000\n",
      "22.4657\t22.2000\n",
      "22.5410\t22.2000\n",
      "21.6975\t22.2000\n",
      "22.5893\t22.3000\n",
      "20.9736\t22.4000\n",
      "22.5951\t22.5000\n",
      "27.1294\t22.5000\n",
      "23.9940\t22.6000\n",
      "18.1498\t22.6000\n",
      "20.4042\t22.7000\n",
      "18.5832\t22.7000\n",
      "24.2929\t22.8000\n",
      "25.1780\t22.9000\n",
      "23.0252\t23.1000\n",
      "18.4574\t23.1000\n",
      "15.7086\t23.2000\n",
      "23.3267\t23.4000\n",
      "26.3320\t23.5000\n",
      "26.0165\t23.6000\n",
      "11.0599\t23.7000\n",
      "26.2199\t23.8000\n",
      "25.2614\t23.9000\n",
      "21.9830\t23.9000\n",
      "27.3832\t24.1000\n",
      "36.9584\t24.3000\n",
      "23.1163\t24.4000\n",
      "21.2094\t24.4000\n",
      "25.8911\t24.4000\n",
      "24.7775\t24.7000\n",
      "31.2260\t24.8000\n",
      "26.3179\t25.0000\n",
      "23.1808\t25.0000\n",
      "22.1684\t25.0000\n",
      "24.9068\t25.2000\n",
      "22.9491\t25.3000\n",
      "26.1991\t26.2000\n",
      "24.8853\t26.4000\n",
      "23.0456\t26.5000\n",
      "28.8674\t26.6000\n",
      "30.0098\t26.6000\n",
      "25.7201\t26.7000\n",
      "38.8565\t27.0000\n",
      "18.0230\t27.1000\n",
      "24.4379\t28.1000\n",
      "28.1220\t28.4000\n",
      "25.2083\t28.6000\n",
      "25.7787\t29.0000\n",
      "31.1578\t29.1000\n",
      "28.9463\t29.4000\n",
      "30.7619\t29.6000\n",
      "29.3789\t29.9000\n",
      "37.7583\t30.1000\n",
      "23.7579\t30.7000\n",
      "30.0359\t31.0000\n",
      "28.9271\t31.2000\n",
      "29.3729\t31.5000\n",
      "33.0336\t31.5000\n",
      "34.6258\t32.9000\n",
      "32.7017\t33.1000\n",
      "30.9517\t33.1000\n",
      "36.2108\t33.3000\n",
      "36.0215\t33.4000\n",
      "33.6223\t34.6000\n",
      "32.5861\t34.9000\n",
      "35.6260\t39.8000\n",
      "43.4098\t41.3000\n",
      "43.8959\t42.3000\n",
      "42.9756\t42.8000\n",
      "43.8659\t44.8000\n",
      "43.9731\t46.0000\n",
      "41.9557\t48.3000\n",
      "46.7886\t50.0000\n",
      "41.0043\t50.0000\n",
      "57.0818\t50.0000\n",
      "46.9898\t50.0000\n",
      "11.627313646903396\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(Xscaled, y, test_size=test_percent, shuffle=True)\n",
    "\n",
    "reg = MLPRegressor(max_iter=10000)\n",
    "\n",
    "reg.fit(X_train, y_train)                         \n",
    "predicted= np.array(reg.predict(X_test))\n",
    "print(\"mse {:.3f}\".format(mse(y_test, predicted)))\n",
    "print('-'*20)\n",
    "\n",
    "pred = reg.predict(X_test)\n",
    "\n",
    "y_sorted = np.argsort(y_test)\n",
    "y_test = y_test[y_sorted]\n",
    "pred = pred[y_sorted]\n",
    "\n",
    "plt.hist(y_test-predicted)\n",
    "plt.show()\n",
    "\n",
    "err = []\n",
    "for p,yact in zip(pred, y_test):\n",
    "    print(\"{:.4f}\\t{:.4f}\".format(p,yact))\n",
    "    v = (p - yact)\n",
    "    err.append(v*v)\n",
    "print(np.mean(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 169.925\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.2000\t5.0000\n",
      "22.4000\t7.0000\n",
      "20.0000\t7.4000\n",
      "10.2000\t8.4000\n",
      "23.9000\t8.4000\n",
      "11.9000\t8.8000\n",
      "19.2000\t10.2000\n",
      "21.4000\t10.5000\n",
      "12.7000\t10.9000\n",
      "13.0000\t12.0000\n",
      "16.7000\t12.6000\n",
      "16.1000\t12.8000\n",
      "22.4000\t13.1000\n",
      "50.0000\t13.1000\n",
      "19.4000\t13.1000\n",
      "11.9000\t13.3000\n",
      "15.3000\t13.5000\n",
      "17.2000\t13.6000\n",
      "22.3000\t13.9000\n",
      "19.4000\t13.9000\n",
      "13.1000\t14.0000\n",
      "23.9000\t14.1000\n",
      "17.1000\t14.1000\n",
      "36.4000\t14.3000\n",
      "13.3000\t14.4000\n",
      "23.2000\t14.9000\n",
      "19.7000\t14.9000\n",
      "50.0000\t15.2000\n",
      "17.4000\t15.6000\n",
      "19.6000\t16.1000\n",
      "17.4000\t16.2000\n",
      "15.7000\t17.0000\n",
      "36.2000\t17.2000\n",
      "7.2000\t17.3000\n",
      "23.2000\t17.5000\n",
      "25.3000\t17.5000\n",
      "6.3000\t18.0000\n",
      "13.8000\t18.2000\n",
      "25.1000\t18.2000\n",
      "28.1000\t18.2000\n",
      "11.9000\t18.3000\n",
      "7.2000\t18.3000\n",
      "22.2000\t18.5000\n",
      "23.6000\t18.6000\n",
      "17.9000\t18.7000\n",
      "12.7000\t18.8000\n",
      "13.3000\t18.8000\n",
      "33.4000\t18.9000\n",
      "17.4000\t19.1000\n",
      "17.7000\t19.1000\n",
      "22.0000\t19.3000\n",
      "19.2000\t19.3000\n",
      "15.2000\t19.6000\n",
      "21.0000\t19.6000\n",
      "29.1000\t19.8000\n",
      "31.5000\t19.9000\n",
      "23.9000\t20.0000\n",
      "32.9000\t20.0000\n",
      "13.2000\t20.1000\n",
      "19.3000\t20.1000\n",
      "7.2000\t20.2000\n",
      "19.2000\t20.2000\n",
      "22.0000\t20.3000\n",
      "24.0000\t20.3000\n",
      "11.7000\t20.4000\n",
      "19.3000\t20.4000\n",
      "31.5000\t20.4000\n",
      "11.9000\t20.5000\n",
      "19.4000\t20.6000\n",
      "16.7000\t20.6000\n",
      "23.2000\t20.6000\n",
      "16.8000\t20.7000\n",
      "16.2000\t21.2000\n",
      "11.9000\t21.4000\n",
      "31.7000\t21.4000\n",
      "48.3000\t21.5000\n",
      "17.8000\t21.5000\n",
      "19.2000\t21.6000\n",
      "36.1000\t21.7000\n",
      "23.3000\t21.9000\n",
      "21.2000\t22.1000\n",
      "21.7000\t22.2000\n",
      "50.0000\t22.2000\n",
      "23.6000\t22.4000\n",
      "19.3000\t22.6000\n",
      "18.5000\t22.6000\n",
      "19.6000\t22.7000\n",
      "22.5000\t22.8000\n",
      "28.1000\t22.8000\n",
      "19.3000\t22.9000\n",
      "22.8000\t23.0000\n",
      "25.1000\t23.0000\n",
      "42.3000\t23.0000\n",
      "23.3000\t23.1000\n",
      "48.3000\t23.1000\n",
      "43.5000\t23.3000\n",
      "37.2000\t23.3000\n",
      "17.4000\t23.5000\n",
      "20.8000\t23.7000\n",
      "17.4000\t23.8000\n",
      "36.2000\t23.8000\n",
      "24.0000\t23.8000\n",
      "33.2000\t23.9000\n",
      "22.5000\t24.1000\n",
      "27.1000\t24.2000\n",
      "21.4000\t24.3000\n",
      "22.0000\t24.6000\n",
      "11.5000\t24.6000\n",
      "19.3000\t24.7000\n",
      "23.2000\t24.8000\n",
      "35.2000\t24.8000\n",
      "10.2000\t24.8000\n",
      "50.0000\t25.0000\n",
      "36.1000\t25.0000\n",
      "15.0000\t27.1000\n",
      "11.9000\t27.5000\n",
      "50.0000\t27.9000\n",
      "19.9000\t27.9000\n",
      "25.3000\t28.0000\n",
      "30.8000\t28.6000\n",
      "18.5000\t28.7000\n",
      "13.2000\t29.0000\n",
      "17.8000\t29.6000\n",
      "21.8000\t29.8000\n",
      "24.7000\t30.5000\n",
      "32.0000\t31.0000\n",
      "19.4000\t31.1000\n",
      "13.2000\t31.5000\n",
      "25.0000\t32.4000\n",
      "23.7000\t33.1000\n",
      "19.3000\t33.2000\n",
      "26.4000\t33.3000\n",
      "25.3000\t34.6000\n",
      "22.0000\t34.7000\n",
      "23.4000\t34.9000\n",
      "7.2000\t35.4000\n",
      "21.8000\t35.4000\n",
      "36.4000\t36.0000\n",
      "11.9000\t37.3000\n",
      "48.8000\t37.6000\n",
      "18.9000\t37.9000\n",
      "15.0000\t41.3000\n",
      "24.5000\t41.7000\n",
      "21.4000\t43.1000\n",
      "15.6000\t44.0000\n",
      "21.7000\t50.0000\n",
      "28.5000\t50.0000\n",
      "13.3000\t50.0000\n",
      "35.1000\t50.0000\n",
      "13.4000\t50.0000\n",
      "30.7000\t50.0000\n",
      "15.0000\t50.0000\n",
      "169.92526315789473\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "reg = tree.DecisionTreeRegressor()\n",
    "reg.fit(X_train, y_train)                         \n",
    "predicted= np.array(reg.predict(X_test))\n",
    "print(\"mse {:.3f}\".format(mse(y_test, predicted)))\n",
    "print('-'*20)\n",
    "\n",
    "pred = reg.predict(X_test)\n",
    "\n",
    "y_sorted = np.argsort(y_test)\n",
    "y_test = y_test[y_sorted]\n",
    "pred = pred[y_sorted]\n",
    "\n",
    "plt.hist(y_test-predicted)\n",
    "plt.show()\n",
    "\n",
    "err = []\n",
    "for p,yact in zip(pred, y_test):\n",
    "    print(\"{:.4f}\\t{:.4f}\".format(p,yact))\n",
    "    v = (p - yact)\n",
    "    err.append(v*v)\n",
    "print(np.mean(err))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
