{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification using Naive Bayes\n",
    "\n",
    "Below are 26 lines of  a T.S. Eliot poem. In each, a dummy string \"ZZZ\" or \"XXX\" has been inserted. The lines comprise the corpus (each string constitutes a document) which will be used to create a Naive Bayes Classifier. \n",
    "\n",
    "Separate from the corpus is a list of 0s and 1s. These indicate the class of each document (the ZZZs and XXXs match the target class). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "'And indeed there will be time ZZZ',\n",
    "'For the yellow smoke that slides along the street XXX',\n",
    "'Rubbing its back upon the window-panes ZZZ',\n",
    "'There will be time, there will be time ZZZ',\n",
    "'To prepare a face to meet the faces that you meet XXX',\n",
    "'There will be time to murder and create ZZZ',\n",
    "'And time for all the works and days of hands ZZZ',\n",
    "'That lift and drop a question on your plate ZZZ',\n",
    "'Time for you and time for me ZZZ',\n",
    "'And time yet for a hundred indecisions XXX',\n",
    "'And for a hundred visions and revisions XXX',\n",
    "'Before the taking of a toast and tea ZZZ.',\n",
    "'In the room the women come and go XXX',\n",
    "'Talking of Michelangelo. XXX',\n",
    "'And indeed there will be time XXX',\n",
    "'To wonder, \"Do I dare?\" and, \"Do I dare?\" ZZZ',\n",
    "'Time to turn back and descend the stair, ZZZ',\n",
    "'With a bald spot in the middle of my hair — XXX',\n",
    "'(They will say: \"How his hair is growing thin!\") XXX',\n",
    "'My morning coat, my collar mounting firmly to the chin, ZZZ',\n",
    "'My necktie rich and modest, but asserted by a simple pin — XXX',\n",
    "'(They will say: \"But how his arms and legs are thin!\") ZZZ',\n",
    "'Do I dare XXX',\n",
    "'Disturb the universe? XXX',\n",
    "'In a minute there is time ZZZ',\n",
    "'For decisions and revisions which a minute will reverse. XXX'\n",
    "]\n",
    "\n",
    "targets = [0,1,0,0,1,0,0,0,0,1,1,0,1,1,1,0,0,1,1,0,1,0,1,1,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import `CountVectorizer` and use it to tokenize and transform the data set. What is produced is a matrix. Each row corresponds to a document, and each column represents a word from the set of all words appearing in the corpus. The matrix cell value represents the number of occurrences of the word in the given document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "rows (docs), columns (words)\n",
      "(26, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(corpus)\n",
    "print('type:',type(X_train_counts))\n",
    "\n",
    "print('rows (docs), columns (words)')\n",
    "print(X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the list of words exptracted from the corpus using `get_feature_names`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'along', 'and', 'are', 'arms', 'asserted', 'back', 'bald', 'be', 'before', 'but', 'by', 'chin', 'coat', 'collar', 'come', 'create', 'dare', 'days', 'decisions', 'descend', 'disturb', 'do', 'drop', 'face', 'faces', 'firmly', 'for', 'go', 'growing', 'hair', 'hands', 'his', 'how', 'hundred', 'in', 'indecisions', 'indeed', 'is', 'its', 'legs', 'lift', 'me', 'meet', 'michelangelo', 'middle', 'minute', 'modest', 'morning', 'mounting', 'murder', 'my', 'necktie', 'of', 'on', 'panes', 'pin', 'plate', 'prepare', 'question', 'reverse', 'revisions', 'rich', 'room', 'rubbing', 'say', 'simple', 'slides', 'smoke', 'spot', 'stair', 'street', 'taking', 'talking', 'tea', 'that', 'the', 'there', 'they', 'thin', 'time', 'to', 'toast', 'turn', 'universe', 'upon', 'visions', 'which', 'will', 'window', 'with', 'women', 'wonder', 'works', 'xxx', 'yellow', 'yet', 'you', 'your', 'zzz']\n",
      "Number of words: 100\n"
     ]
    }
   ],
   "source": [
    "names = count_vect.get_feature_names()\n",
    "print(names)\n",
    "print('Number of words:', len(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the word count for the second line of the poem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0\n",
      " 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "along\n"
     ]
    }
   ],
   "source": [
    "arr = X_train_counts.toarray()[1]\n",
    "print(arr)\n",
    "print(count_vect.get_feature_names()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the vectorized input (using the count of each word, each document can be viewed as a vector), we can create a classifier for it. \n",
    "\n",
    "We'll use `MultinomialNB`, one of scikit-learn's defined Naive Bayes classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data has been fitted, we'll run some new documents through the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For I have known them all already, known them all: ZZZ => 0\n",
      "Have known the evenings, mornings, afternoons, ZZZ => 0\n",
      "I have measured out my life with coffee spoons; XXX => 1\n",
      "I know the voices dying with a dying fall XXX => 1\n",
      "Beneath the music from a farther room. ZZZ => 0\n",
      "So how should I presume? ZZZ => 0\n"
     ]
    }
   ],
   "source": [
    "new_data = [\n",
    "    'For I have known them all already, known them all: ZZZ',\n",
    "    'Have known the evenings, mornings, afternoons, ZZZ',\n",
    "    'I have measured out my life with coffee spoons; XXX',\n",
    "    'I know the voices dying with a dying fall XXX',\n",
    "    'Beneath the music from a farther room. ZZZ',\n",
    "    'So how should I presume? ZZZ']\n",
    "actual = [0,0,1,1,0,0]\n",
    "\n",
    "X_new_counts = count_vect.transform(new_data)\n",
    "\n",
    "predicted = clf.predict(X_new_counts)\n",
    "\n",
    "# zip iterates through new_data and predicted in parallel, forming 2-tuples.\n",
    "for doc, category in zip(new_data, predicted):\n",
    "    print(f'{doc} => {category}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True]\n",
      "accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(predicted == actual)\n",
    "print(\"accuracy\", np.mean(predicted == actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A larger example\n",
    "\n",
    "Taken from: http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "11314\n"
     ]
    }
   ],
   "source": [
    "print(len(twenty_train.data))\n",
    "print(len(twenty_train.filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4,  8, 19,  4, 14,  6,  0,  1,\n",
       "        7, 12,  5,  0, 10,  6,  2,  4,  1, 12,  9, 15,  7,  6, 13, 12, 17,\n",
       "       18, 10,  8, 11,  8, 16,  9,  4,  3,  9,  9,  4,  4,  8, 12, 14,  5,\n",
       "       15,  2, 13, 17, 11,  7, 10,  2, 14, 12,  5,  4,  6,  7,  0, 11, 16,\n",
       "        0,  6, 17,  7, 12,  7,  3, 12, 11,  7,  2,  2,  0, 16,  1,  2,  7,\n",
       "        3,  2,  1, 10, 12, 12, 17, 12,  2,  8,  8, 18,  5,  0,  1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos\n",
      "comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.graphics\n",
      "sci.space\n",
      "talk.politics.guns\n",
      "sci.med\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.mac.hardware\n",
      "rec.motorcycles\n",
      "talk.religion.misc\n",
      "comp.sys.mac.hardware\n",
      "sci.space\n",
      "misc.forsale\n",
      "alt.atheism\n",
      "comp.graphics\n",
      "rec.autos\n",
      "sci.electronics\n",
      "comp.windows.x\n",
      "alt.atheism\n",
      "rec.sport.hockey\n",
      "misc.forsale\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.mac.hardware\n",
      "comp.graphics\n",
      "sci.electronics\n",
      "rec.sport.baseball\n",
      "soc.religion.christian\n",
      "rec.autos\n",
      "misc.forsale\n",
      "sci.med\n",
      "sci.electronics\n",
      "talk.politics.mideast\n",
      "talk.politics.misc\n",
      "rec.sport.hockey\n",
      "rec.motorcycles\n",
      "sci.crypt\n",
      "rec.motorcycles\n",
      "talk.politics.guns\n",
      "rec.sport.baseball\n",
      "comp.sys.mac.hardware\n",
      "comp.sys.ibm.pc.hardware\n",
      "rec.sport.baseball\n",
      "rec.sport.baseball\n",
      "comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware\n",
      "rec.motorcycles\n",
      "sci.electronics\n",
      "sci.space\n"
     ]
    }
   ],
   "source": [
    "for t in twenty_train.target[:50]:\n",
    "    print(twenty_train.target_names[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "#X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "print(type(X_train_counts))\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crescendo', 'crescent', 'crescenta', 'crescentville', 'crest', 'cretaceous', 'cretainly', 'crete', 'cretinous', 'cretins', 'crew', 'crews', 'crg1', 'crg8', 'crgruen', 'crh', 'crhai', 'crhc', 'cri', 'crib', 'cribs', 'crica', 'crichar', 'crichmon', 'crichton', 'crick', 'cricket', 'cried', 'cries', 'criiterion', 'crim', 'crime', 'crimea', 'crimean', 'crimes', 'crimestrike', 'crimial', 'criminal', 'criminality', 'criminalization', 'criminalize', 'criminalized', 'criminally', 'criminals', 'criminological', 'criminologist', 'criminologists', 'criminology', 'crimp', 'crimper']\n"
     ]
    }
   ],
   "source": [
    "names = count_vect.get_feature_names()\n",
    "n = len(names)\n",
    "n = int(n/3)\n",
    "print(names[n:n+50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31636"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get('bald')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "God is love => soc.religion.christian\n",
      "The gods are against us => alt.atheism\n",
      "blood red blood plasma => sci.med\n",
      "OpenGL on the GPU is fast => comp.graphics\n",
      "agnosticism => alt.atheism\n",
      "doubt => soc.religion.christian\n",
      "RAM => comp.sys.mac.hardware\n",
      "Radio Shack => sci.electronics\n",
      "Atari => sci.electronics\n",
      "Brady => talk.politics.guns\n",
      "Saturn => rec.autos\n",
      "Jupiter => sci.space\n"
     ]
    }
   ],
   "source": [
    "docs_new = [\n",
    "    'God is love', \n",
    "    'The gods are against us', \n",
    "    'blood red blood plasma',\n",
    "    'OpenGL on the GPU is fast',\n",
    "    \"agnosticism\",\n",
    "    \"doubt\",\n",
    "    \"RAM\",\n",
    "    \"Radio Shack\",\n",
    "    \"Atari\",\n",
    "    \"Brady\",\n",
    "    \"Saturn\",\n",
    "    \"Jupiter\",\n",
    "]\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "\n",
    "predicted = clf.predict(X_new_counts)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print(f'{doc} => {twenty_train.target_names[category]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
